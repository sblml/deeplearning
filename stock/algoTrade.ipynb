{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from chapter82pytorch, based on Section 8.2 in AlgoTarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from Preprocessing import generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_seq = X_train.shape[1]\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = torch.from_numpy(X_train).float()\n",
    "y_train_ = torch.from_numpy(y_train).long()\n",
    "X_test_ = torch.from_numpy(X_test).float()\n",
    "y_test_ = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_, y_train_)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "def train_loop(epochs, tensorboard=False):\n",
    "    s_ = time.time()\n",
    "    model.train()\n",
    "    size = len(train_dataloader.dataset)\n",
    "    \n",
    "    for e in range(1, epochs+1):\n",
    "        train_loss = 0.\n",
    "        train_score = 0.\n",
    "        if tensorboard:\n",
    "            writer = SummaryWriter(f\"runs/AlgoTradeEpoch{e}\")\n",
    "        \n",
    "        for i, (X, y) in enumerate(train_dataloader, 1):\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "                        \n",
    "            if tensorboard:\n",
    "                for n, p in model.named_parameters():\n",
    "                    if 'weight' in n:\n",
    "                        writer.add_histogram(f\"{n}\", p.grad, i)\n",
    "                        writer.add_scalar(f\"{n}_abs_mean\", p.grad.abs().mean(), i)\n",
    "                        # the name of histogram and scalar should be different, if not, both of them cannot be recognized\n",
    "                writer.close()\n",
    "                \n",
    "            \n",
    "        if e % 10 == 0:\n",
    "            model.eval()\n",
    "            pred = model(X_test_)\n",
    "            loss = loss_fn(pred, y_test_)\n",
    "            correct = (pred.argmax(dim=1) == y_test_).sum()\n",
    "            acc = correct.item() / len(y_test_)\n",
    "            \n",
    "            print(f\"|TRAIN| Epoch: {e:3d}, Loss: {train_loss/i:.6f}   |TEST| Epoch: {e:3d}, Loss: {loss.item():.6f}, Acc: {acc:.2f}\")\n",
    "            model.train()\n",
    "    print(f\"Elapsed time for {time.time() - s_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.BCEWithLogitsLoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|TRAIN| Epoch:  10, Loss: 0.650827   |TEST| Epoch:  10, Loss: 0.744723, Acc: 0.62\n",
      "|TRAIN| Epoch:  20, Loss: 0.651698   |TEST| Epoch:  20, Loss: 0.746222, Acc: 0.60\n",
      "|TRAIN| Epoch:  30, Loss: 0.652120   |TEST| Epoch:  30, Loss: 0.736374, Acc: 0.62\n",
      "|TRAIN| Epoch:  40, Loss: 0.650522   |TEST| Epoch:  40, Loss: 0.746095, Acc: 0.62\n",
      "|TRAIN| Epoch:  50, Loss: 0.650319   |TEST| Epoch:  50, Loss: 0.752180, Acc: 0.62\n",
      "|TRAIN| Epoch:  60, Loss: 0.647589   |TEST| Epoch:  60, Loss: 0.751550, Acc: 0.60\n",
      "|TRAIN| Epoch:  70, Loss: 0.649297   |TEST| Epoch:  70, Loss: 0.756482, Acc: 0.62\n",
      "|TRAIN| Epoch:  80, Loss: 0.646144   |TEST| Epoch:  80, Loss: 0.760549, Acc: 0.62\n",
      "|TRAIN| Epoch:  90, Loss: 0.641986   |TEST| Epoch:  90, Loss: 0.776427, Acc: 0.60\n",
      "|TRAIN| Epoch: 100, Loss: 0.643302   |TEST| Epoch: 100, Loss: 0.776290, Acc: 0.60\n",
      "Elapsed time for 132.99255919456482\n"
     ]
    }
   ],
   "source": [
    "train_loop(epochs=100, tensorboard=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups[0]['lr'] = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Rnn4BN(n_units=150, n_features=n_features)\n",
    "Acc : 0.55\n",
    "    \n",
    "model = Rnn5BN(n_units=200, n_features=n_features)\n",
    "Acc : 0.47 at Epoch 100\n",
    "Acc : 0.62 at Epoch 200\n",
    "Acc : 0.45 at Epoch 300\n",
    "    \n",
    "model = Rnn5BN(n_units=150, n_features=n_features)\n",
    "Acc : 0.47 at Epoch 100\n",
    "Acc : 0.60 at Epoch 200\n",
    "Acc : 0.45 at Epoch 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Rnn5BN(n_units=200, n_features=n_features)\n",
    "Epoch 200 ~ Epoch 300\n",
    "|TRAIN| Epoch:  10, Loss: 0.663524   |TEST| Epoch:  10, Loss: 0.712885, Acc: 0.60\n",
    "|TRAIN| Epoch:  20, Loss: 0.661331   |TEST| Epoch:  20, Loss: 0.716691, Acc: 0.60\n",
    "|TRAIN| Epoch:  30, Loss: 0.661507   |TEST| Epoch:  30, Loss: 0.720340, Acc: 0.60\n",
    "|TRAIN| Epoch:  40, Loss: 0.658665   |TEST| Epoch:  40, Loss: 0.723448, Acc: 0.60\n",
    "|TRAIN| Epoch:  50, Loss: 0.659152   |TEST| Epoch:  50, Loss: 0.727791, Acc: 0.60\n",
    "|TRAIN| Epoch:  60, Loss: 0.656233   |TEST| Epoch:  60, Loss: 0.728771, Acc: 0.60\n",
    "|TRAIN| Epoch:  70, Loss: 0.657999   |TEST| Epoch:  70, Loss: 0.732527, Acc: 0.60\n",
    "|TRAIN| Epoch:  80, Loss: 0.651821   |TEST| Epoch:  80, Loss: 0.733417, Acc: 0.60\n",
    "|TRAIN| Epoch:  90, Loss: 0.653711   |TEST| Epoch:  90, Loss: 0.737276, Acc: 0.62\n",
    "|TRAIN| Epoch: 100, Loss: 0.654109   |TEST| Epoch: 100, Loss: 0.740980, Acc: 0.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Rnn(num_unit=200, seq_len=5)\n",
    "# model = Rnn3BN(n_units=100, n_features=n_features)\n",
    "# model = Rnn4BN(n_units=150, n_features=n_features)\n",
    "model = Rnn5BN(n_units=200, n_features=n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnn(nn.Module):\n",
    "    def __init__(self, n_units, n_features, n_layers=5):\n",
    "        super(Rnn, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(n_features, n_units, n_layers=n_layers, batch_first=True, dropout=0.25)\n",
    "        self.linear1 = nn.Linear(n_units, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, (h_1, c_1) = self.lstm1(x)        \n",
    "        logits = self.linear1(x[:, -1])\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnn3BN(nn.Module):\n",
    "    def __init__(self, n_units, n_features):\n",
    "        super(Rnn3BN, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(n_features, n_units, batch_first=True)\n",
    "        self.ln1 = nn.LayerNorm(n_units)\n",
    "        self.lstm2 = nn.LSTM(n_units, n_units, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.lstm3 = nn.LSTM(n_units, n_units, batch_first=True)\n",
    "        self.ln3 = nn.LayerNorm(n_units)\n",
    "        self.linear1 = nn.Linear(n_units, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, (h_1, c_1) = self.lstm1(x)\n",
    "        x = self.ln1(x)\n",
    "        x, (h_2, c_2) = self.lstm2(x, (h_1, c_1))\n",
    "        x = self.dropout2(x)\n",
    "        x, _ = self.lstm3(x, (h_2, c_2))\n",
    "        x = self.ln3(x)\n",
    "        logits = self.linear1(x[:, -1])\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnn4BN(nn.Module):\n",
    "    def __init__(self, n_units, n_features):\n",
    "        super(Rnn4BN, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(n_features, n_units, batch_first=True)\n",
    "        self.ln1 = nn.LayerNorm(n_units)\n",
    "        self.lstm2 = nn.LSTM(n_units, n_units, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.lstm3 = nn.LSTM(n_units, n_units, batch_first=True)\n",
    "        self.ln3 = nn.LayerNorm(n_units)\n",
    "        self.lstm4 = nn.LSTM(n_units, n_units, batch_first=True)\n",
    "        self.dropout4 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.linear1 = nn.Linear(n_units, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, (h_1, c_1) = self.lstm1(x)\n",
    "        x = self.ln1(x)\n",
    "        x, (h_2, c_2) = self.lstm2(x, (h_1, c_1))\n",
    "        x = self.dropout2(x)\n",
    "        x, (h_3, c_3) = self.lstm3(x, (h_2, c_2))\n",
    "        x = self.ln3(x)\n",
    "        x, (h_4, c_4) = self.lstm4(x, (h_3, c_3))\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "        logits = self.linear1(x[:, -1])\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnn5BN(nn.Module):\n",
    "    def __init__(self, n_units, n_features):\n",
    "        super(Rnn5BN, self).__init__()\n",
    "        self.n_units = n_units\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(n_features, n_units, batch_first=True)\n",
    "        # self.bn1 = nn.BatchNorm1d(batch_size)\n",
    "        self.ln1 = nn.LayerNorm(n_units)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(n_units, n_units, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.lstm3 = nn.LSTM(n_units, n_units, batch_first=True)\n",
    "        # self.bn3 = nn.BatchNorm1d(batch_size)\n",
    "        self.ln3 = nn.LayerNorm(n_units)\n",
    "        \n",
    "        self.lstm4 = nn.LSTM(n_units, n_units, batch_first=True)\n",
    "        self.dropout4 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.lstm5 = nn.LSTM(n_units, n_units, batch_first=True)\n",
    "        # self.bn5 = nn.BatchNorm1d(batch_size)\n",
    "        self.ln5 = nn.LayerNorm(n_units)\n",
    "        \n",
    "        self.linear1 = nn.Linear(n_units, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, (h_1, c_1) = self.lstm1(x)\n",
    "        x = self.ln1(x)\n",
    "        # x = self.bn1(x.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "        \n",
    "        x, (h_2, c_2) = self.lstm2(x, (h_1, c_1))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x, (h_3, c_3) = self.lstm3(x, (h_2, c_2))\n",
    "        x = self.ln3(x)\n",
    "        # x = self.bn3(x.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "        \n",
    "        x, (h_4, c_4) = self.lstm4(x, (h_3, c_3))\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "        x, (h_5, c_5) = self.lstm5(x, (h_4, c_4))\n",
    "        x = self.ln5(x)\n",
    "        # x = self.bn5(x.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "        \n",
    "        logits = self.linear1(x[:, -1])\n",
    "\n",
    "        \n",
    "        return logits  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(29)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred.argmax(1) == y_test_).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred.argmax(dim=1).numpy() == y_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([58, 2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1001e-01,  3.6461e-01],\n",
       "        [-1.0804e+00,  1.3277e+00],\n",
       "        [-8.6788e-01,  1.5455e+00],\n",
       "        [-6.6292e-01,  1.0861e+00],\n",
       "        [-8.1993e-01,  1.2462e+00],\n",
       "        [-3.0072e-01, -8.4105e-02],\n",
       "        [ 3.2806e-02, -3.5405e-01],\n",
       "        [-2.7448e-01,  4.0643e-01],\n",
       "        [-9.3002e-01,  1.2291e+00],\n",
       "        [-6.0369e-02, -1.5818e-01],\n",
       "        [ 1.9017e-01, -2.4336e-01],\n",
       "        [-9.4550e-01,  1.2811e+00],\n",
       "        [-6.0024e-01,  1.4085e+00],\n",
       "        [-1.0060e+00,  1.7116e+00],\n",
       "        [-2.4308e-02, -2.2104e-01],\n",
       "        [-4.5752e-02, -3.0051e-02],\n",
       "        [-2.2287e-02, -2.2116e-01],\n",
       "        [-5.0894e-02, -1.0537e-01],\n",
       "        [-9.9198e-02, -5.3795e-02],\n",
       "        [-4.6180e-02, -1.6504e-01],\n",
       "        [-1.2952e-02, -1.1342e-01],\n",
       "        [-1.3399e-02, -9.6625e-02],\n",
       "        [ 3.1433e-04, -8.7891e-02],\n",
       "        [-2.7498e-02, -9.7061e-02],\n",
       "        [-4.9809e-02, -1.7689e-01],\n",
       "        [-3.0669e-02, -3.9026e-02],\n",
       "        [-1.2183e-01, -4.1537e-02],\n",
       "        [ 6.8738e-03, -1.2762e-01],\n",
       "        [-1.8592e-02, -1.0957e-01],\n",
       "        [-2.6646e-02, -1.8631e-01],\n",
       "        [-8.6333e-02, -8.1009e-02],\n",
       "        [-3.0000e-02, -8.4450e-02],\n",
       "        [-1.4434e-02, -1.0852e-01],\n",
       "        [-6.6318e-02, -1.2127e-01],\n",
       "        [-7.2901e-02, -1.7622e-01],\n",
       "        [-1.0167e-01, -1.0474e-01],\n",
       "        [-8.6217e-02, -8.6482e-02],\n",
       "        [-5.1124e-02, -1.6854e-01],\n",
       "        [-4.4236e-02, -1.1939e-01],\n",
       "        [-3.9379e-02, -2.5858e-01],\n",
       "        [-7.6851e-02, -1.2075e-01],\n",
       "        [-6.7759e-02, -2.1933e-01],\n",
       "        [-6.6545e-02, -1.3545e-01],\n",
       "        [-3.2920e-02, -1.9399e-01],\n",
       "        [-4.2926e-02, -1.9351e-01],\n",
       "        [-8.9245e-02, -9.9385e-02],\n",
       "        [-7.4527e-02, -1.1001e-01],\n",
       "        [-3.3696e-02, -1.4122e-01],\n",
       "        [-5.9062e-02, -1.5266e-01],\n",
       "        [-8.7939e-02, -6.4384e-02],\n",
       "        [-4.2168e-02, -1.5622e-01],\n",
       "        [-6.2491e-03, -1.0367e-01],\n",
       "        [-2.6668e-02, -1.9214e-01],\n",
       "        [-2.3529e-02, -1.0076e-01],\n",
       "        [-1.0519e-02, -5.5357e-02],\n",
       "        [-6.2485e-02, -1.8554e-01],\n",
       "        [-3.6829e-02, -2.0183e-01],\n",
       "        [-2.0828e-02, -2.0175e-01]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3602, 0.6398],\n",
       "        [0.0826, 0.9174],\n",
       "        [0.0822, 0.9178],\n",
       "        [0.1482, 0.8518],\n",
       "        [0.1124, 0.8876],\n",
       "        [0.4461, 0.5539],\n",
       "        [0.5955, 0.4045],\n",
       "        [0.3361, 0.6639],\n",
       "        [0.1035, 0.8965],\n",
       "        [0.5244, 0.4756],\n",
       "        [0.6067, 0.3933],\n",
       "        [0.0974, 0.9026],\n",
       "        [0.1183, 0.8817],\n",
       "        [0.0619, 0.9381],\n",
       "        [0.5490, 0.4510],\n",
       "        [0.4961, 0.5039],\n",
       "        [0.5496, 0.4504],\n",
       "        [0.5136, 0.4864],\n",
       "        [0.4887, 0.5113],\n",
       "        [0.5297, 0.4703],\n",
       "        [0.5251, 0.4749],\n",
       "        [0.5208, 0.4792],\n",
       "        [0.5220, 0.4780],\n",
       "        [0.5174, 0.4826],\n",
       "        [0.5317, 0.4683],\n",
       "        [0.5021, 0.4979],\n",
       "        [0.4799, 0.5201],\n",
       "        [0.5336, 0.4664],\n",
       "        [0.5227, 0.4773],\n",
       "        [0.5398, 0.4602],\n",
       "        [0.4987, 0.5013],\n",
       "        [0.5136, 0.4864],\n",
       "        [0.5235, 0.4765],\n",
       "        [0.5137, 0.4863],\n",
       "        [0.5258, 0.4742],\n",
       "        [0.5008, 0.4992],\n",
       "        [0.5001, 0.4999],\n",
       "        [0.5293, 0.4707],\n",
       "        [0.5188, 0.4812],\n",
       "        [0.5546, 0.4454],\n",
       "        [0.5110, 0.4890],\n",
       "        [0.5378, 0.4622],\n",
       "        [0.5172, 0.4828],\n",
       "        [0.5402, 0.4598],\n",
       "        [0.5376, 0.4624],\n",
       "        [0.5025, 0.4975],\n",
       "        [0.5089, 0.4911],\n",
       "        [0.5269, 0.4731],\n",
       "        [0.5234, 0.4766],\n",
       "        [0.4941, 0.5059],\n",
       "        [0.5285, 0.4715],\n",
       "        [0.5243, 0.4757],\n",
       "        [0.5413, 0.4587],\n",
       "        [0.5193, 0.4807],\n",
       "        [0.5112, 0.4888],\n",
       "        [0.5307, 0.4693],\n",
       "        [0.5412, 0.4588],\n",
       "        [0.5451, 0.4549]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(pred, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([58, 2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 epochs 1e-3, 100 epochs 1e-4, 300 epochs 1e-5\n",
    "|TRAIN| Epoch:  90, Loss: 0.653850   |TEST| Epoch:  90, Loss: 0.691221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.BatchNorm1d(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = net(torch.randn(10, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(preds, torch.randint(0,5, (10,)).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__constants__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_check_input_dim',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'affine',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'bias',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eps',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'half',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'momentum',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_batches_tracked',\n",
       " 'num_features',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'reset_parameters',\n",
       " 'reset_running_stats',\n",
       " 'running_mean',\n",
       " 'running_var',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'track_running_stats',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'weight',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
