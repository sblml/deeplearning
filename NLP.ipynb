{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention is All You Need  \n",
    "introduces the transformer  \n",
    "https://arxiv.org/abs/1706.03762  \n",
    "\n",
    "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
    "relying entirely on an attention mechanism to draw global dependencies between input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT and a brief story of NLP  \n",
    "https://rosinality.github.io/2018/10/bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pretraining for NLP  \n",
    "think of resnet for CV  \n",
    "https://github.com/google-research/bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoBertA  \n",
    "https://jeongukjae.github.io/posts/3-roberta-review/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://www.kaggle.com/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model  \n",
    "https://www.slideshare.net/abhishekkrthakur/approaching-almost-any-nlp-problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to study  \n",
    "https://wikidocs.net/22893"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Textdata preprocessing  \n",
    "tokernizer = get_tokenizer('basic_english')  \n",
    "counter.update(tokenizer(string))\n",
    "Vocab(counter) : build vocab  \n",
    "generate numerical dataset: for text in datasets: [vocab[token] for token in tokenizer(text)] : words to integers\n",
    "\n",
    "Note that the entire texts go through counter to build vocab  \n",
    "and go through again to vocab[token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate batch, acceptable for networks\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "receives a list of tensors with different sizes, each tensor represents a sample\n",
    "returns a tensor, a batch padded\n",
    "\n",
    "[Tensor([1,2]), Tensor([1,2,3,4,5])] -> \n",
    " tensor([[1, 1],\n",
    "        [2, 2],\n",
    "        [0, 3],\n",
    "        [0, 4],\n",
    "        [0, 5]])\n",
    "\n",
    "Note that the batch returned is adapted for RNN, transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq-to-Seq: translation, Q&A, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Module in NLP receives integer indices first\n",
    "and immediatly transform integers to a vector throguh Embedding\n",
    "therefore, the first layer in NLP would be Embedding\n",
    "\n",
    "GRU, LSTM, RNN, TransformerEncoder, etc. follows\n",
    "Attention mechanism process input with encoder_outputs before passing to GRU\n",
    "\n",
    "then LinearLayer follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER receives and processed the entire sequence at once, input (len_seq, B, )\n",
    "DECODER processes each element in the sequence one by one, input(1, B, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECODER\n",
    "the first input for decoder will be <SOS>\n",
    "the first output will be the second input\n",
    "\n",
    "the first hidden is the last hidden from encoder\n",
    "\n",
    "therefore NOTE that, for decoder, the output dim == the input dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention: confer inputs processed with the current hidden state to output a result  \n",
    "See Section3 in https://wikidocs.net/22893"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "From NLPfromScratch3.ipynb\n",
    "\n",
    "torch.bmm: batch-matrix-multiplication, bmm with (10, 3, 4) and (10, 4, 5) -> (10, 3, 5)\n",
    "\n",
    "attn_weights (1, MAX_LENGTH)\n",
    "encoder_outputs (MAX_LENGTH, hidden_size)\n",
    "CHECK : why MAX_LENGTH? may be for accounting for inputs\n",
    "\n",
    "bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0)) -> attn_applied\n",
    "(1, 1, MAX_LENGTH) * (1, MAX_LENGTH, hidden_size) -> (1, 1, hidden_size)\n",
    "\n",
    "encoder_outputs is not directly referred,\n",
    "but is multiplied by attention weights in bmm and adjusted to attn_applied before using\n",
    "\n",
    "one encoder output for one word is (1, hidden_size) vector\n",
    "encoder_outputs (MAX_LENGTH, hidden_size) is a collection of (1, hidden_size) vectors of MAX_LENGTH words \n",
    "MAX_LENGTH encoder outputs multiplied by corresponding weights condensed to (1, hidden_size) like one word encoder output\n",
    "\n",
    "each weight element <-> each input word\n",
    "[0, 0, 0.5, 0.5, 0] means 3rd 4th words are important at this decoding step\n",
    "\n",
    "weights are obtained from input and previous hidden as context\n",
    "\n",
    "attn_combine\n",
    "combines the information in the input and the transformed encoder_outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use nn.Transformer module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "positional encoding  \n",
    "https://kazemnejad.com/blog/transformer_architecture_positional_encoding/  \n",
    "https://skyjwoo.tistory.com/entry/positional-encoding%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchtext  \n",
    ".data.utils.get_tokenizer  \n",
    ".vocab.Vocab  \n",
    "vocab, word vectors, tokenizer  \n",
    "the basic data processing building blocks for raw text string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The vocabulary block converts a list of tokens into integers.\n",
    "[vocab[token] for token in ['here', 'is', 'an', 'example']]\n",
    ">>> [476, 22, 31, 5298]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/text/stable/vocab.html  \n",
    "vocab.stoi(token) == vocab[token]  \n",
    "vocab[token] is the key for the token, an integer  \n",
    "vocab.stoi returns the entire dict  \n",
    "len(vocab.stoi) the size of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.GRU(input_size, hidden_size)  \n",
    "input_size : the size of input feature, dim 2  \n",
    "hidden_size : determines the size of output feature, dim 2\n",
    "    \n",
    "(l, B, input_size) -> (l, B, hidden_size), only the size of dim 2 changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec : pretrained embedding vectors  \n",
    "nn.Embedding : train embedding vectors by myself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Embedding(ntoken, ninp)  \n",
    "(\\*) -> (\\*, H), i.e., add a dimension of size H at the end  \n",
    "[B, 1] -> [B, 1, ninp], an index to a vector, i.e. an integer to a vector  \n",
    "the index is in the range (0, ntoken)  \n",
    "ntoken would be a vacab size\n",
    "\n",
    "THINK of an array of shape (n_vocab, d_embedding)  \n",
    "given an index, returns [index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.EmbeddingBag  \n",
    "shape (n_all_words_in_batch) with offsets -> (B, encoding_dim)  \n",
    "words in a batch reduced to (1, encodimg_dim)\n",
    "\n",
    "nn.EmbeddingBag with the default mode of “mean” computes the mean value of a “bag” of embeddings. Although the text entries here have different lengths, nn.EmbeddingBag module requires no padding here since the text lengths are saved in offsets.\n",
    "\n",
    "bags are like batches with different size  \n",
    "one word to one embedding  \n",
    "a batch to a bag of embeddings\n",
    "\n",
    "with mode=\"sum\" is equivalent to Embedding followed by torch.sum(dim=1),\n",
    "\n",
    "with mode=\"mean\" is equivalent to Embedding followed by torch.mean(dim=1),\n",
    "\n",
    "with mode=\"max\" is equivalent to Embedding followed by torch.max(dim=1).\n",
    "\n",
    "However, EmbeddingBag is much more time and memory efficient than using a chain of these operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offsets required to cut each batch\n",
    "with offsets, each batch can have different sizes without padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://czxttkl.com/2020/01/14/embeddingbag-from-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = [5, 3, 10]\n",
    "bathc2 = [27, 10, 30, 2, 5]\n",
    "different length of batches acceptable with offsets\n",
    "\n",
    "for batch1\n",
    "5 -> an array of (encoding_dim), 3-> an array, 10-> an array\n",
    "three arrays are averaged to be an array of (encoding_dim)\n",
    "\n",
    "nn.EmbeddingBag(30, 3)([5,3,10,27,10,30,2,5], [0,3]) -> of shape (2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Embedding maps an integer to a vector  \n",
    "nn.EmbeddingBag maps integers, a batch, to a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.TransformerEncoder consists of multiple layers of nn.TransformerEncoderLayer.  \n",
    "https://pytorch.org/tutorials/_images/transformer_architecture.jpg  \n",
    "Nx nn.TransformerEncoderLayer in the picture form a TransformerEncoder\n",
    "\n",
    "nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, activation)  \n",
    "with d_model=512, nhead=8, (10, 32, 512) -> (10, 32, 512) in the example  \n",
    "d_model : feature input\n",
    "nhead: the number of arrows to Multi-Head Attention in the picture  \n",
    "dim_feedforward  \n",
    "d_model determines the input and output shape\n",
    "\n",
    "nn.TransformerEncoder(encoder_layer, num_layers)  \n",
    "with encoder_layer=the layer above, num_layers=6, (10, 32, 512) -> (10, 32, 512) in the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "get_tokenizer('basic_enlgish')\n",
    "get_tokenizer('spacy', lanauge='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'machine learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 'machine learning'),\n",
       " ('m', 'achine learning'),\n",
       " ('ma', 'chine learning'),\n",
       " ('mac', 'hine learning'),\n",
       " ('mach', 'ine learning'),\n",
       " ('machi', 'ne learning'),\n",
       " ('machin', 'e learning'),\n",
       " ('machine', ' learning'),\n",
       " ('machine ', 'learning'),\n",
       " ('machine l', 'earning'),\n",
       " ('machine le', 'arning'),\n",
       " ('machine lea', 'rning'),\n",
       " ('machine lear', 'ning'),\n",
       " ('machine learn', 'ing'),\n",
       " ('machine learni', 'ng'),\n",
       " ('machine learnin', 'g'),\n",
       " ('machine learning', '')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(word[:i], word[i:]) for i in range(len(word)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [(word[:i], word[i:]) for i in range(len(word)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['achine learning',\n",
       " 'mchine learning',\n",
       " 'mahine learning',\n",
       " 'macine learning',\n",
       " 'machne learning',\n",
       " 'machie learning',\n",
       " 'machin learning',\n",
       " 'machinelearning',\n",
       " 'machine earning',\n",
       " 'machine larning',\n",
       " 'machine lerning',\n",
       " 'machine leaning',\n",
       " 'machine learing',\n",
       " 'machine learnng',\n",
       " 'machine learnig',\n",
       " 'machine learnin']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[L + R[1:] for L, R in splits if R]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(5) if i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2d = [[1,2,3,4,5], [6,7,8,9,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[elm for arr1d in arr2d for elm in arr1d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
